{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb7c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sakth\\anaconda3\\envs\\Recruitbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import typing as t\n",
    "import math\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from fastapi import FastAPI, UploadFile, File, Form, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from pypdf import PdfReader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86e7d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sakth\\AppData\\Local\\Temp\\ipykernel_26356\\3010391511.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  EMBEDDINGS = HuggingFaceEmbeddings(model_name=EMB_MODEL, model_kwargs={\"device\": \"cpu\"})\n"
     ]
    }
   ],
   "source": [
    "EMB_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EMBEDDINGS = HuggingFaceEmbeddings(model_name=EMB_MODEL, model_kwargs={\"device\": \"cpu\"})\n",
    "\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "RETRIEVE_K = 6\n",
    "\n",
    "# In-memory memory store: { jd_name: { \"best\": {...}, \"history\": [ {...}, ... ] } }\n",
    "MEMORY_STORE: dict = {}\n",
    "\n",
    "app = FastAPI(title=\"JD-Resume RAG Evaluator (in-memory LangServe-like)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb61fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(path: str) -> str:\n",
    "    reader = PdfReader(path)\n",
    "    text = []\n",
    "    for p in reader.pages:\n",
    "        t = p.extract_text()\n",
    "        if t:\n",
    "            text.append(t)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def chunk_text(text: str, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "def create_rag_store_from_text(text: str):\n",
    "    chunks = chunk_text(text)\n",
    "    if not chunks:\n",
    "        return {\"vectorstore\": None, \"chunks\": []}\n",
    "    vectorstore = FAISS.from_texts(texts=chunks, embedding=EMBEDDINGS)\n",
    "    return {\"vectorstore\": vectorstore, \"chunks\": chunks}\n",
    "\n",
    "def create_rag_store_from_pdf(path: str):\n",
    "    text = extract_pdf_text(path)\n",
    "    return create_rag_store_from_text(text)\n",
    "\n",
    "def retrieve_top_text(store: dict, query: str, k=RETRIEVE_K) -> str:\n",
    "    vs = store.get(\"vectorstore\")\n",
    "    if vs is None:\n",
    "        return \"\"\n",
    "    retriever = vs.as_retriever(search_kwargs={\"k\": k})\n",
    "    # modern LangChain retriever is a runnable - use .invoke()\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\".join([d.page_content for d in docs]) if docs else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f93c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a: t.List[float], b: t.List[float]) -> float:\n",
    "    # simple cos similarity\n",
    "    dot = sum(x*y for x,y in zip(a,b))\n",
    "    na = math.sqrt(sum(x*x for x in a))\n",
    "    nb = math.sqrt(sum(x*x for x in b))\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return dot / (na*nb)\n",
    "\n",
    "def embed_text(text: str):\n",
    "    # HuggingFaceEmbeddings wrapper provides embed_query or embed_documents methods\n",
    "    # Use embed_query for a single vector\n",
    "    if not text:\n",
    "        return []\n",
    "    return EMBEDDINGS.embed_query(text)\n",
    "\n",
    "def extract_keywords(text: str, top_n=20):\n",
    "    # naive keyword extraction: most common words after filtering stopwords / short tokens\n",
    "    if not text:\n",
    "        return []\n",
    "    tokens = re.findall(r\"[A-Za-z+#\\.\\-]+\", text.lower())\n",
    "    stop = {\"the\",\"and\",\"for\",\"with\",\"that\",\"this\",\"from\",\"your\",\"you\",\"have\",\"are\",\"will\",\"his\",\"her\",\"our\",\"a\",\"an\",\"to\",\"in\",\"on\",\"of\",\"by\"}\n",
    "    freq = {}\n",
    "    for tkn in tokens:\n",
    "        if len(tkn) < 3: continue\n",
    "        if tkn in stop: continue\n",
    "        freq[tkn] = freq.get(tkn,0)+1\n",
    "    sorted_tokens = sorted(freq.items(), key=lambda x: -x[1])\n",
    "    return [t for t,_ in sorted_tokens[:top_n]]\n",
    "\n",
    "def skill_match_score(jd_text: str, resume_text: str) -> float:\n",
    "    # compute overlap of keywords\n",
    "    jd_keys = set(extract_keywords(jd_text, top_n=40))\n",
    "    res_keys = set(extract_keywords(resume_text, top_n=80))\n",
    "    if not jd_keys:\n",
    "        return 0.0\n",
    "    overlap = jd_keys.intersection(res_keys)\n",
    "    return float(len(overlap)) / float(len(jd_keys))\n",
    "\n",
    "def experience_score_from_resume(resume_text: str) -> float:\n",
    "    # crude heuristic: find \"X years\" pattern and map to score\n",
    "    m = re.search(r\"(\\d{1,2})\\s+years?\", resume_text.lower())\n",
    "    if m:\n",
    "        years = int(m.group(1))\n",
    "        if years >= 10:\n",
    "            return 1.0\n",
    "        if years >= 5:\n",
    "            return 0.8\n",
    "        if years >= 2:\n",
    "            return 0.6\n",
    "        return 0.4\n",
    "    # fallback: look for \"senior|mid|junior\"\n",
    "    if re.search(r\"\\bsenior\\b\", resume_text, re.I):\n",
    "        return 0.95\n",
    "    if re.search(r\"\\bmid[- ]?level\\b|\\bmidlevel\\b\", resume_text, re.I):\n",
    "        return 0.75\n",
    "    if re.search(r\"\\bjunior\\b|\\bentry\\b\", resume_text, re.I):\n",
    "        return 0.35\n",
    "    return 0.5  # unknown baseline\n",
    "\n",
    "def compute_suitability(jd_store: dict, resume_store: dict) -> dict:\n",
    "    # get whole-text approximations: join top-k retrieved chunks to create short context for scoring\n",
    "    jd_context = \"\\n\".join(jd_store.get(\"chunks\", [])[:10]) if jd_store.get(\"chunks\") else \"\"\n",
    "    resume_context = \"\\n\".join(resume_store.get(\"chunks\", [])[:20]) if resume_store.get(\"chunks\") else \"\"\n",
    "\n",
    "    # semantic similarity (embed full contexts)\n",
    "    jd_vec = embed_text(jd_context) or []\n",
    "    resume_vec = embed_text(resume_context) or []\n",
    "    sem_sim = cosine_sim(jd_vec, resume_vec) if jd_vec and resume_vec else 0.0\n",
    "\n",
    "    # skill match score (keyword overlap)\n",
    "    skill_score = skill_match_score(jd_context, resume_context)\n",
    "\n",
    "    # experience score heuristic\n",
    "    exp_score = experience_score_from_resume(resume_context)\n",
    "\n",
    "    # combine into single suitability score with weights (tweakable)\n",
    "    # weights: semantic 40%, skill overlap 40%, experience 20%\n",
    "    suitability = 0.4 * sem_sim + 0.4 * skill_score + 0.2 * exp_score\n",
    "\n",
    "    # normalize to 0..100 for readability\n",
    "    suitability_pct = round(float(suitability) * 100, 2)\n",
    "\n",
    "    return {\n",
    "        \"semantic_similarity\": round(sem_sim, 4),\n",
    "        \"skill_overlap\": round(skill_score, 4),\n",
    "        \"experience_score\": round(exp_score, 4),\n",
    "        \"suitability_score\": suitability_pct\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a07d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/evaluate\")\n",
    "async def evaluate_jd_resume(\n",
    "    jd_name: str = Form(...),\n",
    "    jd_file: UploadFile = File(...),\n",
    "    resume_file: UploadFile = File(...),\n",
    "    replace_if_better: bool = Form(True)\n",
    "):\n",
    "    \"\"\"\n",
    "    Accepts multipart form:\n",
    "      - jd_name: unique identifier for JD (string)\n",
    "      - jd_file: PDF for job description\n",
    "      - resume_file: PDF for candidate resume\n",
    "      - replace_if_better: if true, store resume as best only if its score is better.\n",
    "    Returns JSON with detailed scores and comparison with memory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Save uploaded files temporarily\n",
    "    tmp_dir = tempfile.mkdtemp(prefix=\"rag_evaluate_\")\n",
    "    try:\n",
    "        jd_path = os.path.join(tmp_dir, f\"jd_{jd_file.filename}\")\n",
    "        resume_path = os.path.join(tmp_dir, f\"resume_{resume_file.filename}\")\n",
    "\n",
    "        with open(jd_path, \"wb\") as f:\n",
    "            f.write(await jd_file.read())\n",
    "        with open(resume_path, \"wb\") as f:\n",
    "            f.write(await resume_file.read())\n",
    "\n",
    "        # Build RAG stores\n",
    "        jd_store = create_rag_store_from_pdf(jd_path)\n",
    "        resume_store = create_rag_store_from_pdf(resume_path)\n",
    "\n",
    "        # compute suitability\n",
    "        metrics = compute_suitability(jd_store, resume_store)\n",
    "\n",
    "        # Comparison with memory\n",
    "        record = MEMORY_STORE.get(jd_name)\n",
    "        verdict = \"first_for_jd\"\n",
    "        replaced = False\n",
    "        previous = None\n",
    "\n",
    "        if record is None:\n",
    "            # first one for this JD -> store as best\n",
    "            MEMORY_STORE[jd_name] = {\n",
    "                \"best\": {\n",
    "                    \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                    \"jd_file\": jd_path,\n",
    "                    \"resume_file\": resume_path,\n",
    "                    \"metrics\": metrics\n",
    "                },\n",
    "                \"history\": [\n",
    "                    {\n",
    "                        \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                        \"resume_file\": resume_path,\n",
    "                        \"metrics\": metrics\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            verdict = \"stored_as_best\"\n",
    "            replaced = True\n",
    "        else:\n",
    "            prev_best = record[\"best\"][\"suitability_score\"]\n",
    "            previous = record[\"best\"]\n",
    "            if metrics[\"suitability_score\"] > prev_best:\n",
    "                verdict = \"better_than_previous\"\n",
    "                if replace_if_better:\n",
    "                    # replace best and append history\n",
    "                    record[\"history\"].append({\n",
    "                        \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                        \"resume_file\": resume_path,\n",
    "                        \"metrics\": metrics\n",
    "                    })\n",
    "                    record[\"best\"] = {\n",
    "                        \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                        \"jd_file\": jd_path,\n",
    "                        \"resume_file\": resume_path,\n",
    "                        \"metrics\": metrics\n",
    "                    }\n",
    "                    replaced = True\n",
    "            elif metrics[\"suitability_score\"] < prev_best:\n",
    "                verdict = \"worse_than_previous\"\n",
    "                record[\"history\"].append({\n",
    "                    \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                    \"resume_file\": resume_path,\n",
    "                    \"metrics\": metrics\n",
    "                })\n",
    "            else:\n",
    "                verdict = \"same_as_previous\"\n",
    "                record[\"history\"].append({\n",
    "                    \"suitability_score\": metrics[\"suitability_score\"],\n",
    "                    \"resume_file\": resume_path,\n",
    "                    \"metrics\": metrics\n",
    "                })\n",
    "\n",
    "        # Build response\n",
    "        resp = {\n",
    "            \"jd_name\": jd_name,\n",
    "            \"metrics\": metrics,\n",
    "            \"verdict\": verdict,\n",
    "            \"replaced_best\": replaced,\n",
    "            \"previous_best\": previous,\n",
    "            \"memory_summary\": {\n",
    "                \"best_score\": MEMORY_STORE[jd_name][\"best\"][\"suitability_score\"] if jd_name in MEMORY_STORE else None,\n",
    "                \"history_count\": len(MEMORY_STORE[jd_name][\"history\"]) if jd_name in MEMORY_STORE else 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return JSONResponse(resp)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        # NOTE: keep files if stored as best (we saved resume_path into memory). If not stored, cleanup.\n",
    "        # We remove tmp_dir only if it no longer contains saved best files\n",
    "        # Simple safe cleanup: do not delete if stored in memory as best to keep resume path valid.\n",
    "        # If first time stored_as_best we already stored those paths in MEMORY_STORE; avoid deleting them.\n",
    "        # If not stored, remove tmp files.\n",
    "        record_after = MEMORY_STORE.get(jd_name)\n",
    "        # If record_after exists and its best resume_file is inside tmp_dir, we KEEP tmp_dir (so keep files),\n",
    "        # otherwise cleanup.\n",
    "        keep = False\n",
    "        if record_after:\n",
    "            best_path = record_after[\"best\"].get(\"resume_file\")\n",
    "            if best_path and best_path.startswith(tmp_dir):\n",
    "                keep = True\n",
    "        if not keep:\n",
    "            try:\n",
    "                shutil.rmtree(tmp_dir)\n",
    "            except Exception:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929fe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recruitbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
